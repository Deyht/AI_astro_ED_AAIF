{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **IRIS TensorFlow**\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Deyht/AI_astro_ED_AAIF/blob/main/practical_works/mlp/tensorflow/iris/iris_colab_notebook.ipynb)\n"
      ],
      "metadata": {
        "id": "-JogTBRD-Cus"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTUQpT91-Avc"
      },
      "outputs": [],
      "source": [
        "%cd /content/\n",
        "\n",
        "import os\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "######################### ##########################\n",
        "#          Loading data and pre process\n",
        "######################### ##########################\n",
        "\n",
        "if(not os.path.isdir(\"iris_data\")):\n",
        "\t\tos.system(\"wget https://share.obspm.fr/s/Hpbnot5JMoRpSQS/download/iris_data.tar.gz\")\n",
        "\t\tos.system(\"tar -xzf iris_data.tar.gz\")\n",
        "\n",
        "raw_data = np.loadtxt(\"iris_data/iris.data\")\n",
        "\n",
        "nb_dat = np.shape(raw_data)[0]\n",
        "in_dim = np.shape(raw_data)[1] - 1\n",
        "out_dim = 3\n",
        "\n",
        "input = raw_data[:,:in_dim]\n",
        "\n",
        "targ = np.zeros((nb_dat,out_dim))\n",
        "for i in range(0,nb_dat):\n",
        "\ttarg[i,int(raw_data[i,in_dim])] = 1.0\n",
        "\n",
        "\n",
        "input[:,:] -= np.mean(input[:,:], axis = 0)\n",
        "input[:,:] /= np.max(np.abs(input[:,:]), axis = 0)\n",
        "\n",
        "train = input[:100,:]\n",
        "train_targ = targ[:100,:]\n",
        "\n",
        "valid = input[100:,:]\n",
        "valid_targ = targ[100:,:]\n",
        "\n",
        "\n",
        "######################### ##########################\n",
        "#         Loading the neural network model\n",
        "######################### ##########################\n",
        "\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(layers.Dense(units=8, activation='sigmoid'))\n",
        "model.add(layers.Dense(units=3, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(train, train_targ, batch_size=8, epochs=800, shuffle=True,  validation_split=0.0, validation_data=(valid, valid_targ))\n",
        "\n",
        "model.evaluate(valid, valid_targ)\n",
        "\n",
        "pred = model.predict(valid)\n",
        "\n",
        "matrix = metrics.confusion_matrix(valid_targ.argmax(axis=1), pred.argmax(axis=1))\n",
        "\n",
        "print (matrix)"
      ]
    }
  ]
}