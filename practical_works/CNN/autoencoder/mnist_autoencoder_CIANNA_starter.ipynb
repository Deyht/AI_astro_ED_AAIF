{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **MNIST AutoEncoder notebook**\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Deyht/AI_astro_ED_AAIF/blob/main/codes/CNN/autoencoder/mnist_autoencoder_CIANNA.ipynb)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Link to the CIANNA github repository**\n",
        "https://github.com/Deyht/CIANNA"
      ],
      "metadata": {
        "id": "JfKCrIlDu-E0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CIANNA installation**"
      ],
      "metadata": {
        "id": "vIXMFIFmvYzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Query GPU allocation and properties\n",
        "\n",
        "If nvidia-smi fail, it might indicate that you launched the colab session whithout GPU reservation.  \n",
        "To change the type of reservation go to \"Runtime\"->\"Change runtime type\" and select \"GPU\" as your hardware accelerator."
      ],
      "metadata": {
        "id": "Ke8s2bCZvk1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "nvidia-smi\n",
        "\n",
        "cd /content/\n",
        "\n",
        "git clone https://github.com/NVIDIA/cuda-samples/\n",
        "\n",
        "cd /content/cuda-samples/Samples/1_Utilities/deviceQuery/\n",
        "\n",
        "cmake CMakeLists.txt\n",
        "\n",
        "make SMS=\"50 60 70 80\"\n",
        "\n",
        "./deviceQuery | grep Capability | cut -c50- > ~/cuda_infos.txt\n",
        "./deviceQuery | grep \"CUDA Driver Version / Runtime Version\" | cut -c57- >> ~/cuda_infos.txt\n",
        "\n",
        "cd ~/"
      ],
      "metadata": {
        "id": "AHq06Uwk49Ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are granted a GPU that supports high FP16 compute scaling (e.g the Tesla T4), it is advised to change the mixed_precision parameter in the prediction to \"FP16C_FP32A\".  \n",
        "See the detail description on mixed precision support with CIANNA on the [Systeme Requirements](https://github.com/Deyht/CIANNA/wiki/1\\)-System-Requirements) wiki page."
      ],
      "metadata": {
        "id": "tZ-lmHiRBFwt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Clone CIANNA git repository"
      ],
      "metadata": {
        "id": "A1SJ6-x8vqsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/\n",
        "\n",
        "git clone https://github.com/Deyht/CIANNA\n",
        "\n",
        "cd CIANNA"
      ],
      "metadata": {
        "id": "_uptvrov55YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compiling CIANNA for the allocated GPU generation\n",
        "\n",
        "There is no guaranteed forward or backward compatibility between Nvidia GPU generation, and some capabilities are generation specific. For these reasons, CIANNA must be provided the platform GPU generation at compile time.\n",
        "The following cell will automatically update all the necessary files based on the detected GPU, and compile CIANNA."
      ],
      "metadata": {
        "id": "JYGPC3OUv0td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/CIANNA\n",
        "\n",
        "mult=\"10\"\n",
        "cat ~/cuda_infos.txt\n",
        "comp_cap=\"$(sed '1!d' ~/cuda_infos.txt)\"\n",
        "cuda_vers=\"$(sed '2!d' ~/cuda_infos.txt)\"\n",
        "\n",
        "lim=\"11.1\"\n",
        "old_arg=$(awk '{if ($1 < $2) print \"-D CUDA_OLD\";}' <<<\"${cuda_vers} ${lim}\")\n",
        "\n",
        "sm_val=$(awk '{print $1*$2}' <<<\"${mult} ${comp_cap}\")\n",
        "\n",
        "gen_val=$(awk '{if ($1 >= 80) print \"-D GEN_AMPERE\"; else if($1 >= 70) print \"-D GEN_VOLTA\";}' <<<\"${sm_val}\")\n",
        "\n",
        "sed -i \"s/.*arch=sm.*/\\\\t\\tcuda_arg=\\\"\\$cuda_arg -D CUDA -D comp_CUDA -lcublas -lcudart -arch=sm_$sm_val $old_arg $gen_val\\\"/g\" compile.cp\n",
        "sed -i \"s/\\/cuda-[0-9][0-9].[0-9]/\\/cuda-$cuda_vers/g\" compile.cp\n",
        "sed -i \"s/\\/cuda-[0-9][0-9].[0-9]/\\/cuda-$cuda_vers/g\" src/python_module_setup.py\n",
        "\n",
        "./compile.cp CUDA PY_INTERF\n",
        "\n",
        "mv src/build/lib.linux-x86_64-* src/build/lib.linux-x86_64"
      ],
      "metadata": {
        "id": "HGJUvmWW7YE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testing CIANNA installation\n",
        "\n",
        "**IMPORTANT NOTE**   \n",
        "CIANNA is mainly used in a script fashion and was not designed to run in notebooks. Every cell code that directly invokes CIANNA functions must be run as a script to avoid possible errors.  \n",
        "To do so, the cell must have the following structure.\n",
        "\n",
        "```\n",
        "%%shell\n",
        "\n",
        "cd /content/CIANNA\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "[... your python code ...]\n",
        "\n",
        "EOF\n",
        "```\n",
        "\n",
        "This syntax allows one to easily edit python code in the notebook while running the cell as a script. Note that all the notebook variables can not be accessed by the cell in this context.\n"
      ],
      "metadata": {
        "id": "vbnBhbIL8wv1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AutoEncoder training"
      ],
      "metadata": {
        "id": "3rfFYMmPrpnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from threading import Thread\n",
        "import os, sys, glob\n",
        "\n",
        "import albumentations as A\n",
        "import cv2\n",
        "\n",
        "sys.path.insert(0,glob.glob('/content/CIANNA/src/build/lib.*/')[-1])\n",
        "import CIANNA as cnn\n",
        "\n",
        "def i_ar(int_list):\n",
        "\treturn np.array(int_list, dtype=\"int\")\n",
        "\n",
        "def f_ar(float_list):\n",
        "\treturn np.array(float_list, dtype=\"float32\")\n",
        "\n",
        "if(not os.path.isdir(\"mnist_dat\")):\n",
        "\tos.system(\"wget https://share.obspm.fr/s/EkYR5B2Wc2gNis3/download/mnist.tar.gz\")\n",
        "\tos.system(\"tar -xvzf mnist.tar.gz\")\n",
        "\n",
        "if(not os.path.isdir(\"fig\")):\n",
        "\tos.system(\"mkdir fig\")\n",
        "\n",
        "#Add data augmentation to increase the diversity\n",
        "transform = A.Compose([\n",
        "\tA.Affine(scale={\"x\":[0.90,1.0],\"y\":[0.90,1.0]}, rotate=[-10,10], fit_output=True, mode=cv2.BORDER_CONSTANT, cval=0.025),\n",
        "\tA.LongestMaxSize(max_size=28),\n",
        "\tA.PadIfNeeded(min_height=28, min_width=28, value=0.025),\n",
        "])\n",
        "\n",
        "image_size = 28\n",
        "\n",
        "data = np.fromfile(\"mnist_dat/mnist_input.dat\", dtype=\"float32\")\n",
        "data = np.reshape(data, (80000,image_size*image_size))*0.95 + 0.025\n",
        "\n",
        "#Train on the combination of tain and valid dataset from MNIST to improve diversity\n",
        "nb_train = 70000\n",
        "\n",
        "data_train = data[:nb_train,:]\n",
        "data_valid = data[nb_train:,:]\n",
        "\n",
        "iter_size = 65536\n",
        "\n",
        "def create_batch(visual=0):\n",
        "\n",
        "\tdata = np.zeros((iter_size,image_size*image_size), dtype=\"float32\")\n",
        "\n",
        "\tif(visual):\n",
        "\t\tfig, axs = plt.subplots(4, 5, figsize=(10,8), dpi=300, constrained_layout=True)\n",
        "\n",
        "\tfor i in range(0,iter_size):\n",
        "\n",
        "\t\ti_d = int(np.random.random()*nb_train)\n",
        "\n",
        "\t\tif(np.random.random() < 0.5):\n",
        "\t\t\ttransformed = transform(image=np.reshape(data_train[i_d],(image_size,image_size)))\n",
        "\t\t\tpatch = transformed['image']\n",
        "\t\telse:\n",
        "\t\t\tpatch = np.reshape(data_train[i_d],(image_size,image_size))\n",
        "\n",
        "\t\tdata[i,:] = patch.flatten(\"C\")\n",
        "\n",
        "\t\tif(visual and i < 4*5):\n",
        "\t\t\taxs[i//5][i%5].imshow(patch, vmax=1.0, vmin=0.0, interpolation=\"bilinear\", cmap=\"Greys\")\n",
        "\t\t\taxs[i//5][i%5].axis('off')\n",
        "\n",
        "\tif(visual):\n",
        "\t\tplt.savefig(\"train_img.png\", dpi=300)\n",
        "\n",
        "\treturn data\n",
        "\n",
        "def data_augm_fct():\n",
        "\tdata_augm = create_batch(0)\n",
        "\tcnn.delete_dataset(\"TRAIN_buf\", silent=1)\n",
        "\tcnn.create_dataset(\"TRAIN_buf\", iter_size, data_augm, data_augm, silent=1)\n",
        "\treturn\n",
        "\n",
        "\n",
        "cnn.init(in_dim=i_ar([image_size,image_size]), in_nb_ch=1, out_dim=image_size*image_size,\n",
        "\t\tbias=0.1, b_size=32, comp_meth=\"C_CUDA\", #Change to C_BLAS or C_NAIV\n",
        "\t\tdynamic_load=1, mixed_precision=\"FP16C_FP32A\")\n",
        "\n",
        "data_augm = create_batch(1)\n",
        "cnn.create_dataset(\"TRAIN\", size=iter_size, input=data_augm, target=data_augm)\n",
        "cnn.create_dataset(\"VALID\", size=80000-nb_train, input=data_valid, target=data_valid)\n",
        "cnn.create_dataset(\"TEST\" , size=32, input=data_valid[:32], target=data_valid[:32])\n",
        "\n",
        "a_relu = cnn.relu(leaking=0.1, saturation=640000.0)\n",
        "a_lin = cnn.relu(leaking=1.0, saturation=640000.0)\n",
        "\n",
        "load_step = 0\n",
        "if(load_step > 0):\n",
        "\tcnn.load(\"net_save/net0_s%04d.dat\"%(load_step), load_step)\n",
        "else:\n",
        "\n",
        "  #Define your autoencoder architecture here\n",
        "\n",
        "  #Encoder first, can be a classical CNN with compresion of the spatial dimension\n",
        "\n",
        "  #[...]\n",
        "\n",
        "  #The latent space here must be 2D, corresponding to the following layer\n",
        "  cnn.dense(nb_neurons=2, stric_size=1, activation=a_lin)\n",
        "\n",
        "  #Then, the decoder, that should expand back the spatial dimension to the original image size\n",
        "\n",
        "  #[...]\n",
        "\n",
        "  #When connecting a dense layer to a conv layer you need to specify the input shape.\n",
        "  #The number of neurons in your previous layer must correspond. (use strict_size=1 on a dense layer that connect to a conv layer)\n",
        "  cnn.conv(f_size=[...], nb_filters=[...], padding=[...], activation=[...], input_shape=i_ar([DIM_W,DIM_H,DIM_D,NB_CHANNELS]))\n",
        "\n",
        "  #To invert the effect of a pooling layer or a stride=2 convolutional layer you can add internal padding to a conv layer.\n",
        "  #Here the following setup expand by a factor of 2 in each spatial dimensions\n",
        "\n",
        "  #The decoder last layer must have the same number of channels that the input (here 1)\n",
        "  # and an activation function that covers the possible input range (here normalized to LIN or LOGI are fine)\n",
        "  cnn.conv(f_size=[...], nb_filters=1 , padding=[...], activation=\"LOGI\")\n",
        "\n",
        "\n",
        "for i in range(load_step,100):\n",
        "\n",
        "  t = Thread(target=data_augm_fct)\n",
        "  t.start()\n",
        "\n",
        "  cnn.train(nb_iter=1, learning_rate=VAL, end_learning_rate=VAL, lr_decay=VAL, momentum=VAL, confmat=0, save_every=50, TC_scale_factor=16.0)\n",
        "\n",
        "  t.join()\n",
        "\n",
        "  if(i == 0):\n",
        "    cnn.perf_eval()\n",
        "\n",
        "  cnn.swap_data_buffers(\"TRAIN\")\n",
        "\n",
        "  #Draw the input/targets and predictions for a subset of the valid/test sample every 10 iterations\n",
        "  if((i+1)%10 == 0):\n",
        "    patch_in = np.zeros((image_size,image_size))\n",
        "    patch_out = np.zeros((image_size,image_size))\n",
        "\n",
        "    cnn.forward(saving=2, no_error=1, silent=1, drop_mode=\"AVG_MODEL\")\n",
        "    fwd_dat = np.fromfile(\"fwd_res/net0_%04d.dat\"%(i+1), dtype=\"float32\")\n",
        "    fwd_dat = np.reshape(fwd_dat,(32,image_size*image_size))\n",
        "\n",
        "    fig, axs = plt.subplots(5, 4, figsize=(6,7.5), dpi=int(image_size*2.0), constrained_layout=True)\n",
        "    for j in range(0,2*5):\n",
        "      axs[int(j/2)][int((j%2)*2)].axis('off')\n",
        "      axs[int(j/2)][int((j%2)*2+1)].axis('off')\n",
        "\n",
        "      fig.suptitle(\"Epoch %d\"%(i+1))\n",
        "\n",
        "    for j in range(0,2*5):\n",
        "      patch_in[:,:] = np.reshape(fwd_dat[j][:],(image_size,image_size))\n",
        "      patch_out[:,:] = np.reshape(data_valid[j][:],(image_size,image_size))\n",
        "\n",
        "      axs[int(j/2)][int((j%2)*2)].imshow(patch_in, interpolation=\"bilinear\", cmap=\"Greys\")\n",
        "      axs[int(j/2)][int((j%2)*2+1)].imshow(patch_out, interpolation=\"bilinear\", cmap=\"Greys\")\n",
        "\n",
        "    plt.savefig(\"fig/fwd_%04d.png\"%(i+1), dpi=int(image_size*2.0))\n",
        "    plt.close()\n",
        "\n",
        "EOF"
      ],
      "metadata": {
        "id": "29EfNLjyrp6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize the latent space"
      ],
      "metadata": {
        "id": "-SRQBNHauIwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cmap\n",
        "from matplotlib.lines import Line2D\n",
        "from threading import Thread\n",
        "import os, sys, glob\n",
        "\n",
        "import albumentations as A\n",
        "import cv2\n",
        "\n",
        "sys.path.insert(0,glob.glob('/content/CIANNA/src/build/lib.*/')[-1])\n",
        "import CIANNA as cnn\n",
        "\n",
        "def i_ar(int_list):\n",
        "\treturn np.array(int_list, dtype=\"int\")\n",
        "\n",
        "def f_ar(float_list):\n",
        "\treturn np.array(float_list, dtype=\"float32\")\n",
        "\n",
        "\n",
        "if(not os.path.isdir(\"mnist_dat\")):\n",
        "\tos.system(\"wget https://share.obspm.fr/s/EkYR5B2Wc2gNis3/download/mnist.tar.gz\")\n",
        "\tos.system(\"tar -xvzf mnist.tar.gz\")\n",
        "\n",
        "image_size = 28\n",
        "\n",
        "data = np.fromfile(\"mnist_dat/mnist_input.dat\", dtype=\"float32\")\n",
        "data = np.reshape(data, (80000,image_size*image_size))*0.95+0.025\n",
        "target = np.fromfile(\"mnist_dat/mnist_target.dat\", dtype=\"float32\")\n",
        "target = np.reshape(target, (80000,10))\n",
        "\n",
        "data_valid = data[70000:,:]\n",
        "\n",
        "cnn.init(in_dim=i_ar([image_size,image_size]), in_nb_ch=1, out_dim=2,\n",
        "\t\tbias=0.1, b_size=32, comp_meth=\"C_CUDA\", #Change to C_BLAS or C_NAIV\n",
        "\t\tdynamic_load=1, mixed_precision=\"FP16C_FP32A\")\n",
        "\n",
        "cnn.create_dataset(\"TEST\", size=10000, input=data_valid, target=np.zeros((10000,2), dtype=\"float32\"))\n",
        "\n",
        "load_step = 0\n",
        "if(load_step > 0):\n",
        "  #Specify the number of layers to load from the autoencoder save file to stop at the latent space\n",
        "\tcnn.load(\"net_save/net0_s%04d.dat\"%(load_step), nb_layers=8, iteration=load_step)\n",
        "\n",
        "cnn.forward(saving=2, no_error=1, silent=0, drop_mode=\"AVG_MODEL\")\n",
        "fwd_dat = np.fromfile(\"fwd_res/net0_%04d.dat\"%(load_step), dtype=\"float32\")\n",
        "fwd_dat = np.reshape(fwd_dat,(10000,3))\n",
        "\n",
        "plt.scatter(fwd_dat[:,0], fwd_dat[:,1], s=0.4,\n",
        "\tc=cmap.tab10(np.argmax(target[70000:,:], axis=1)))\n",
        "\n",
        "handles, labels = plt.gca().get_legend_handles_labels()\n",
        "\n",
        "for i in range(0,10):\n",
        "\thandles.append(Line2D([0], [0], marker='o', color=cmap.tab10(i), markersize=8))\n",
        "\tlabels.append(\"%d\"%(i))\n",
        "\n",
        "plt.legend(handles, labels)\n",
        "plt.savefig(\"latent_space_visual.png\")\n",
        "\n",
        "EOF"
      ],
      "metadata": {
        "id": "R8ygN_qDuSp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "im = Image.open(\"latent_space_visual.png\")\n",
        "plt.figure(dpi=200)\n",
        "plt.imshow(im)\n",
        "plt.gca().axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DlsHEIj87MFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate new digits using the decoder from the latent space\n",
        "\n",
        "In order to run only the decoder part, it is necessary to generate a save_file model that only contains the decoder layers. This can be done by opening the full autoencoder save file (net_save/net0_s%04d.dat) in ascii and deleting all the layers corresponding to the encoder. The input shape also need to be updated to correspond to the size of the latent space."
      ],
      "metadata": {
        "id": "6e4uYEQ1ssLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from threading import Thread\n",
        "import os, sys, glob\n",
        "\n",
        "import albumentations as A\n",
        "import cv2\n",
        "\n",
        "sys.path.insert(0,glob.glob('/content/CIANNA/src/build/lib.*/')[-1])\n",
        "import CIANNA as cnn\n",
        "\n",
        "if(not os.path.isdir(\"mnist_dat\")):\n",
        "\tos.system(\"wget https://share.obspm.fr/s/EkYR5B2Wc2gNis3/download/mnist.tar.gz\")\n",
        "\tos.system(\"tar -xvzf mnist.tar.gz\")\n",
        "\n",
        "def i_ar(int_list):\n",
        "\treturn np.array(int_list, dtype=\"int\")\n",
        "\n",
        "def f_ar(float_list):\n",
        "\treturn np.array(float_list, dtype=\"float32\")\n",
        "\n",
        "nb_r = 8\n",
        "nb_theta = 60\n",
        "\n",
        "r_range = [3,25]\n",
        "theta_range = [0,2*np.pi]\n",
        "\n",
        "radius_sampling = np.linspace(r_range[0],r_range[1],nb_r)\n",
        "theta_sampling = np.linspace(theta_range[0],theta_range[1],nb_theta,endpoint=False)\n",
        "\n",
        "lat_coords = np.zeros((nb_r,nb_theta,2))\n",
        "\n",
        "for i in range(0,nb_r):\n",
        "\tr = radius_sampling[i]\n",
        "\tfor j in range(0,nb_theta):\n",
        "\t\ttheta = theta_sampling[j]\n",
        "\t\tlat_coords[i,j,:] = [r*np.cos(theta), r*np.sin(theta)]\n",
        "\n",
        "plt.scatter(lat_coords[:,:,0].flatten(), lat_coords[:,:,1].flatten())\n",
        "plt.show()\n",
        "\n",
        "image_size = 28\n",
        "\n",
        "empty_targets = np.zeros((nb_r*nb_theta,image_size*image_size), dtype=\"float32\")\n",
        "\n",
        "cnn.init(in_dim=i_ar([2]), in_nb_ch=1, out_dim=image_size*image_size,\n",
        "\t\tbias=0.1, b_size=32, comp_meth=\"C_CUDA\", #Change to C_BLAS or C_NAIV\n",
        "\t\tdynamic_load=1, mixed_precision=\"FP16C_FP32A\")\n",
        "\n",
        "cnn.create_dataset(\"TEST\", size=nb_r*nb_theta, input=f_ar(np.reshape(lat_coords,(nb_r*nb_theta,2))), target=empty_targets)\n",
        "\n",
        "cnn.load(\"MNIST_decoder.dat\", iteration=0)\n",
        "\n",
        "cnn.forward(saving=2, no_error=1, silent=0, drop_mode=\"AVG_MODEL\")\n",
        "fwd_dat = np.fromfile(\"fwd_res/net0_%04d.dat\"%(0), dtype=\"float32\")\n",
        "fwd_dat = np.reshape(fwd_dat,(nb_r*nb_theta,image_size*image_size))\n",
        "\n",
        "fig, axs = plt.subplots(nb_theta, nb_r, figsize=(nb_r*1, nb_theta*1), layout=\"constrained\")\n",
        "\n",
        "for ax in axs.flatten():\n",
        "\tax.axis(\"off\")\n",
        "\n",
        "for j in range(0,nb_theta):\n",
        "\tfor i in range(0,nb_r):\n",
        "\t\taxs[j,i].imshow(fwd_dat[i*nb_theta+j].reshape((image_size,image_size)), cmap=\"Greys\")\n",
        "\n",
        "plt.savefig(\"generated_digits.png\",dpi=100)\n",
        "\n",
        "EOF"
      ],
      "metadata": {
        "id": "w80PquU9srzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "im = Image.open(\"generated_digits.png\")\n",
        "plt.figure(dpi=800)\n",
        "plt.imshow(im)\n",
        "plt.gca().axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u2AXaod877Ht"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}