{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **ASIRRA TensorFlow**\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Deyht/AI_astro_ED_AAIF/blob/main/practical_works/CNN/classification/ASIRRA_TensorFlow.ipynb)\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "JfKCrIlDu-E0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ASIRRA**\n",
        "\n",
        "The ASIRRA (Animal Species Image Recognition for Restricting Access) is a dataset that was originally used for CAPTCHA and HIP (Human Interactive Proofs).\n",
        "\n",
        "The original dataset comprises 25000 images of variable resolution (averaging around 350x500) and is equally distributed over the two classes \"Cat\" and \"Dog\". For this exercise, we provide two reduced versions in the form of padded and resized RGB images at either 128x128 or 256x256 as two binary files. This construction is necessary so the dataset can fit into the limited amount of Colab RAM. You can download one or both sets to test the impact of the input resolution on your network. In these files, the first 12500 images are of Cats, and the next 12500 are of Dogs. The last 1024 images of each class will be excluded to form our reference test dataset (total size 2048)."
      ],
      "metadata": {
        "id": "gd2waB3JYNkx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Downloading and visualizing the data\n",
        "\n",
        "We start by downloading and visualizing the raw data. You can get one or both of the resized versions."
      ],
      "metadata": {
        "id": "pW4pvpjKbZiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content\n",
        "\n",
        "wget https://share.obspm.fr/s/6TBsCpAASeETH3S/download/asirra_bin_128.tar.gz\n",
        "tar -xvzf asirra_bin_128.tar.gz\n",
        "\n",
        "#wget https://share.obspm.fr/s/52nxyfn7PjzawSe/download/asirra_bin_256.tar.gz\n",
        "#tar -xvzf asirra_bin_256.tar.gz"
      ],
      "metadata": {
        "id": "_crOekcVbEpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "image_size = 128\n",
        "\n",
        "v_width = 8; v_height = 5\n",
        "nb_images = v_width*v_height\n",
        "\n",
        "f_im_s = image_size*image_size*3\n",
        "\n",
        "subset_cats = np.reshape(np.fromfile(\"asirra_bin_%d.dat\"%(image_size),\n",
        "  dtype=\"uint8\", count=f_im_s*(nb_images//2)), (nb_images//2,image_size,image_size,3))\n",
        "\n",
        "subset_dogs = np.reshape(np.fromfile(\"asirra_bin_%d.dat\"%(image_size),\n",
        "  dtype=\"uint8\", count=f_im_s*(nb_images//2), offset=12500*f_im_s), (nb_images//2,image_size,image_size,3))\n",
        "\n",
        "fig, ax = plt.subplots(v_height, v_width, figsize=(v_width*1.5,v_height*1.5), dpi=200, constrained_layout=True)\n",
        "\n",
        "for i in range(0, v_width*v_height):\n",
        "  c_x = i // v_width; c_y = i % v_width\n",
        "  p_c = int((i)%2) #Alternate cats and dogs in display\n",
        "  if(p_c == 0):\n",
        "    ax[c_x,c_y].imshow(subset_cats[i//2])\n",
        "  else:\n",
        "    ax[c_x,c_y].imshow(subset_dogs[i//2])\n",
        "  ax[c_x,c_y].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-PsyIg0sZmSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training a network\n",
        "\n",
        "Edit the following cells to train a network architecture on the ASIRRA dataset"
      ],
      "metadata": {
        "id": "so4ypoJhLFkr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training a network\n",
        "\n"
      ],
      "metadata": {
        "id": "6ZeV1bvjRS4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "\n",
        "import numpy as np\n",
        "from threading import Thread\n",
        "import gc, os, sys, glob\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn import metrics\n",
        "import tensorflow as tf\n",
        "\n"
      ],
      "metadata": {
        "id": "6R3l1EKah4eH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_count = 12500\n",
        "nb_class = 2\n",
        "\n",
        "nb_keep_val = 1024\n",
        "\n",
        "image_size_raw = 128\n",
        "image_size = 128\n",
        "#working image size can be lowered to increase computation speed\n",
        "\n",
        "batch_size = 16\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "raw_data_array = np.reshape(np.fromfile(\"asirra_bin_128.dat\", dtype=\"uint8\"), (class_count*2,image_size_raw,image_size_raw,3))\n",
        "\n",
        "train_examples = np.append(raw_data_array[:class_count-nb_keep_val], raw_data_array[class_count:-nb_keep_val], axis=0)\n",
        "test_examples = np.append(raw_data_array[class_count-nb_keep_val:class_count], raw_data_array[-nb_keep_val:], axis=0)\n",
        "\n",
        "del(raw_data_array)\n",
        "gc.collect()\n",
        "\n",
        "train_labels = np.zeros((np.shape(train_examples)[0],nb_class))\n",
        "test_labels = np.zeros((np.shape(test_examples)[0],nb_class))\n",
        "\n",
        "train_labels[:class_count-nb_keep_val,0] = 1.0\n",
        "train_labels[class_count-nb_keep_val:,1] = 1.0\n",
        "\n",
        "test_labels[:nb_keep_val,0] = 1.0\n",
        "test_labels[nb_keep_val:,1] = 1.0\n",
        "\n",
        "#Alternate classes for better shuffle starting point\n",
        "buf_train_examples = np.copy(train_examples)\n",
        "buf_train_labels = np.copy(train_labels)\n",
        "\n",
        "buf_train_examples[::2] = train_examples[:class_count-nb_keep_val]\n",
        "buf_train_examples[1::2] = train_examples[class_count-nb_keep_val:]\n",
        "\n",
        "buf_train_labels[::2] = train_labels[:class_count-nb_keep_val]\n",
        "buf_train_labels[1::2] = train_labels[class_count-nb_keep_val:]\n",
        "\n",
        "train_examples = buf_train_examples\n",
        "train_labels = buf_train_labels\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_examples, train_labels))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_examples, test_labels))\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "resize_and_rescale = tf.keras.Sequential([\n",
        "  layers.Resizing(image_size, image_size),\n",
        "  layers.Rescaling(1./255)\n",
        "])\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.RandomFlip('horizontal',\n",
        "        input_shape=(image_size, image_size, 3)),\n",
        "  layers.RandomRotation(factor=(-0.1, 0.1), fill_mode='constant'),\n",
        "  layers.RandomZoom(height_factor=(-0.2,0.2), width_factor=(-0.2,0.2), fill_mode='constant'),\n",
        "  layers.RandomContrast(0.2),\n",
        "  layers.RandomBrightness(0.2, value_range=(0.0, 1.0))\n",
        "])\n",
        "\n",
        "\n",
        "def prepare(ds, shuffle=False, augment=False):\n",
        "  ds = ds.map(lambda x, y: (resize_and_rescale(x), y),\n",
        "              num_parallel_calls=AUTOTUNE)\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(1000)\n",
        "\n",
        "  ds = ds.batch(batch_size)\n",
        "\n",
        "  if augment:\n",
        "    ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y),\n",
        "                num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "  return ds.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "train_dataset = prepare(train_dataset, shuffle=True, augment=True)\n",
        "test_dataset = prepare(test_dataset)\n",
        "\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "id": "PaXxG3jKiBTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "total_iter = 10\n",
        "\n",
        "load_iter = 0\n",
        "\n",
        "if(load_iter > 0):\n",
        "\tmodel = models.models.load('%04d.keras'%(load_iter))\n",
        "else:\n",
        "\tmodel = keras.Sequential()\n",
        "\n",
        "\t#Add your architecture here\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "for run_iter in range(load_iter,total_iter):\n",
        "\n",
        "\tmodel.fit(train_dataset, batch_size=batch_size, epochs=1, shuffle=True, validation_data=test_dataset)\n",
        "\n",
        "\tmodel.save('%04d.keras'%(run_iter+1))\n",
        "\n",
        "\tpred = model.predict(test_dataset)\n",
        "\n",
        "\tmatrix = metrics.confusion_matrix(test_labels.argmax(axis=1), pred.argmax(axis=1))\n",
        "\tprint (matrix)\n",
        "\n",
        "#print(model.summary())\n",
        "\n"
      ],
      "metadata": {
        "id": "MvRhvumeRWZY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}