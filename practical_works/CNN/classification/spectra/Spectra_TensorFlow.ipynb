{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **TensorFlow Stellar Spectra**\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Deyht/AI_astro_ED_AAIF/blob/main/practical_works/CNN/classification/spectra/Spectra_TensorFlow.ipynb)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Link to the CIANNA github repository**\n",
        "https://github.com/Deyht/CIANNA"
      ],
      "metadata": {
        "id": "JfKCrIlDu-E0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "import sys, glob\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn import metrics\n",
        "import tensorflow as tf\n",
        "\n",
        "############################################################################\n",
        "##              Data reading (your mileage may vary)\n",
        "############################################################################\n",
        "\n",
        "\n",
        "if(not os.path.isdir(\"stellar_spectra_data\")):\n",
        "\t\tos.system(\"wget https://share.obspm.fr/s/ANxKkxAZoKmXzRw/download/stellar_spectra_data.tar.gz\")\n",
        "\t\tos.system(\"tar -xzf stellar_spectra_data.tar.gz\")\n",
        "\n",
        "print (\"Reading inputs ... \", end = \"\", flush=True)\n",
        "\n",
        "nb_class = 7\n",
        "raw_spectra_size = 3753\n",
        "spectra_size = 3776\n",
        "nb_spectra = 1115\n",
        "nb_keep_val = 200\n",
        "\n",
        "class_balance = [10,30,30,20,20,30,10]\n",
        "nb_train = np.sum(class_balance) # rebalanced over 1115\n",
        "\n",
        "######################### ##########################\n",
        "#          Loading data and pre process\n",
        "######################### ##########################\n",
        "\n",
        "raw_data = np.loadtxt(\"stellar_spectra_data/train.dat\")\n",
        "raw_target = np.loadtxt(\"stellar_spectra_data/target.dat\")\n",
        "\n",
        "input = np.tanh(40*np.clip(raw_data,0.,1.))\n",
        "targ = raw_target\n",
        "\n",
        "id_classes = []\n",
        "for i in range(0, nb_class):\n",
        "\ttemp = np.where(np.argmax(targ[:,:], axis=1) == i)\n",
        "\tid_classes.append(temp)\n",
        "\n",
        "input[:,:] -= np.mean(input[:,:], axis = 0)\n",
        "input[:,:] /= np.max(np.abs(input[:,:]), axis = 0)\n",
        "\n",
        "# split training and test dataset\n",
        "input_test = input[-nb_keep_val:,:]\n",
        "targ_test = targ[-nb_keep_val:,:]\n",
        "\n",
        "print (np.shape(input_test))\n",
        "\n",
        "input_train = np.empty((0,raw_spectra_size))\n",
        "targ_train = np.empty((0,nb_class))\n",
        "\n",
        "for i in range(0,nb_class):\n",
        "\tindex_list = id_classes[i][0][:class_balance[i]]\n",
        "\tfor j in range(0, len(index_list)):\n",
        "\t\tinput_train = np.append(input_train, np.reshape(input[index_list[j],:],(1,raw_spectra_size)), axis=0)\n",
        "\t\ttarg_train = np.append(targ_train, np.reshape(targ[index_list[j],:],(1,nb_class)), axis=0)\n",
        "\n",
        "pad_in_train = np.zeros((nb_train, spectra_size))\n",
        "pad_in_test = np.zeros((nb_keep_val, spectra_size))\n",
        "\n",
        "pre_pad = np.maximum(0,(spectra_size - raw_spectra_size)//2)\n",
        "post_pad = np.maximum(0,(spectra_size - raw_spectra_size)//2 + (spectra_size - raw_spectra_size)%2)\n",
        "\n",
        "pad_in_train[:,pre_pad:-post_pad] = input_train[:,:]\n",
        "pad_in_test[:,pre_pad:-post_pad] = input_test[:,:]\n",
        "\n",
        "#Reshape to allow initial padding in the model\n",
        "pad_in_train = np.reshape(pad_in_train, (nb_train,spectra_size,1))\n",
        "pad_in_test = np.reshape(pad_in_test, (nb_keep_val,spectra_size,1))\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.ZeroPadding1D(padding=2))\n",
        "model.add(layers.Conv1D(filters=8 , kernel_size=8, strides=4, activation='relu'))\n",
        "model.add(keras.layers.ZeroPadding1D(padding=2))\n",
        "model.add(layers.Conv1D(filters=16, kernel_size=8, strides=4, activation='relu'))\n",
        "model.add(keras.layers.ZeroPadding1D(padding=2))\n",
        "model.add(layers.Conv1D(filters=32, kernel_size=8, strides=4, activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(units=256))\n",
        "model.add(layers.Dropout(0.4))\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.Dense(units=256))\n",
        "model.add(layers.Dropout(0.4))\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.Dense(units=nb_class, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "for run_iter in range(0,4):\n",
        "\n",
        "\tmodel.fit(pad_in_train, targ_train, batch_size=16, epochs=50, shuffle=True, validation_data=(pad_in_test, targ_test))\n",
        "\n",
        "\tpred = model.predict(pad_in_test)\n",
        "\n",
        "\tmatrix = metrics.confusion_matrix(targ_test.argmax(axis=1), pred.argmax(axis=1))\n",
        "\tprint (matrix)\n",
        "\n"
      ],
      "metadata": {
        "id": "2L-7ZffT9Ayq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
