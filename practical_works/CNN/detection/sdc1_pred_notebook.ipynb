{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **YOLO-CIANNA SDC1 example script**\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Deyht/CIANNA/blob/CIANNA/examples/SKAO_SDC1/sdc1_pred_notebook.ipynb)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Link to the CIANNA github repository**\n",
        "https://github.com/Deyht/CIANNA"
      ],
      "metadata": {
        "id": "JfKCrIlDu-E0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SDC1 prediction network\n",
        "\n",
        "This notebook is a simplified version of the scripts used in Cornu et al. 2024\n",
        "presenting the application of the YOLO-CIANNA method over the SKAO SDC1 dataset.\n",
        "This notebook can be used to reproduce the reference result of the paper by\n",
        "downloading the corresponding saved network model.\n",
        "\n",
        "This notebook does not re-train a network from scratch, it only load the trained model,\n",
        "and do the prediction on the full image.\n",
        "Training scripts are provided in the SKAO SDC1 example directory in the CIANNA repository/\n",
        "\n",
        "Most of the data processing work is done in aux_fct.py and data_gen.py.\n",
        "We strongly encourage having a look at this script to understand the processing done in this notebook.\n"
      ],
      "metadata": {
        "id": "4y-JKSQxfc_3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1- **CIANNA installation**"
      ],
      "metadata": {
        "id": "vIXMFIFmvYzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Query GPU allocation and properties\n",
        "\n",
        "If nvidia-smi fail, it might indicate that you launched the colab session whithout GPU reservation.  \n",
        "To change the type of reservation go to \"Runtime\"->\"Change runtime type\" and select \"GPU\" as your hardware accelerator."
      ],
      "metadata": {
        "id": "Ke8s2bCZvk1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "nvidia-smi\n",
        "\n",
        "cd /content/\n",
        "\n",
        "git clone https://github.com/NVIDIA/cuda-samples/\n",
        "\n",
        "cd /content/cuda-samples/Samples/1_Utilities/deviceQuery/\n",
        "\n",
        "cmake CMakeLists.txt\n",
        "\n",
        "make SMS=\"50 60 70 80\"\n",
        "\n",
        "./deviceQuery | grep Capability | cut -c50- > ~/cuda_infos.txt\n",
        "./deviceQuery | grep \"CUDA Driver Version / Runtime Version\" | cut -c57- >> ~/cuda_infos.txt\n",
        "\n",
        "cd ~/"
      ],
      "metadata": {
        "id": "AHq06Uwk49Ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are granted a GPU that does not support FP16 computation, it is advised to change the mixed precision method to FP32C_FP32A in the corresponding cells.\n",
        "See the detail description on mixed precision support with CIANNA on the [Systeme Requirements](https://github.com/Deyht/CIANNA/wiki/1\\)-System-Requirements) wiki page."
      ],
      "metadata": {
        "id": "tZ-lmHiRBFwt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Clone CIANNA git repository"
      ],
      "metadata": {
        "id": "A1SJ6-x8vqsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/\n",
        "\n",
        "git clone https://github.com/Deyht/CIANNA\n",
        "\n",
        "cd CIANNA"
      ],
      "metadata": {
        "id": "_uptvrov55YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compiling CIANNA for the allocated GPU generation\n",
        "\n",
        "There is no guaranteed forward or backward compatibility between Nvidia GPU generation, and some capabilities are generation specific. For these reasons, CIANNA must be provided the platform GPU generation at compile time.\n",
        "The following cell will automatically update all the necessary files based on the detected GPU, and compile CIANNA."
      ],
      "metadata": {
        "id": "JYGPC3OUv0td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/CIANNA\n",
        "\n",
        "mult=\"10\"\n",
        "cat ~/cuda_infos.txt\n",
        "comp_cap=\"$(sed '1!d' ~/cuda_infos.txt)\"\n",
        "cuda_vers=\"$(sed '2!d' ~/cuda_infos.txt)\"\n",
        "\n",
        "lim=\"11.1\"\n",
        "old_arg=$(awk '{if ($1 < $2) print \"-D CUDA_OLD\";}' <<<\"${cuda_vers} ${lim}\")\n",
        "\n",
        "sm_val=$(awk '{print $1*$2}' <<<\"${mult} ${comp_cap}\")\n",
        "\n",
        "gen_val=$(awk '{if ($1 >= 80) print \"-D GEN_AMPERE\"; else if($1 >= 70) print \"-D GEN_VOLTA\";}' <<<\"${sm_val}\")\n",
        "\n",
        "sed -i \"s/.*arch=sm.*/\\\\t\\tcuda_arg=\\\"\\$cuda_arg -D CUDA -D comp_CUDA -lcublas -lcudart -arch=sm_$sm_val $old_arg $gen_val\\\"/g\" compile.cp\n",
        "sed -i \"s/\\/cuda-[0-9][0-9].[0-9]/\\/cuda-$cuda_vers/g\" compile.cp\n",
        "sed -i \"s/\\/cuda-[0-9][0-9].[0-9]/\\/cuda-$cuda_vers/g\" src/python_module_setup.py\n",
        "\n",
        "./compile.cp CUDA PY_INTERF\n",
        "\n",
        "mv src/build/lib.linux-x86_64-* src/build/lib.linux-x86_64"
      ],
      "metadata": {
        "id": "HGJUvmWW7YE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CIANNA notebook guideline\n",
        "\n",
        "**IMPORTANT NOTE**   \n",
        "CIANNA is mainly used in a script fashion and was not designed to run in notebooks. Every cell code that directly invokes CIANNA functions must be run as a script to avoid possible errors.  \n",
        "To do so, the cell must have the following structure.\n",
        "\n",
        "```\n",
        "%%shell\n",
        "\n",
        "cd /content/CIANNA\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "[... your python code ...]\n",
        "\n",
        "EOF\n",
        "```\n",
        "\n",
        "This syntax allows one to easily edit python code in the notebook while running the cell as a script. Note that all the notebook variables can not be accessed by the cell in this context.\n"
      ],
      "metadata": {
        "id": "vbnBhbIL8wv1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 - Detector prediction\n",
        "Run pred_network.py whith no parameters after updating the cnn.init() parameters for your config\n",
        "*   It will download the trained model\n",
        "*   It will perform a prediction on the full image and save it in raw prediction formal\n"
      ],
      "metadata": {
        "id": "q5VWfgLv8KRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "pip install ska_sdc"
      ],
      "metadata": {
        "id": "O0nUsUwUC9uE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%shell\n",
        "\n",
        "cd /content/CIANNA/examples/SKAO_SDC1/\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "from threading import Thread\n",
        "from data_gen import *\n",
        "\n",
        "#Comment to access system wide install\n",
        "sys.path.insert(0,glob.glob(\"../../src/build/lib.*/\")[-1])\n",
        "import CIANNA as cnn\n",
        "\n",
        "\n",
        "def i_ar(int_list):\n",
        "    return np.array(int_list, dtype=\"int\")\n",
        "\n",
        "def f_ar(float_list):\n",
        "    return np.array(float_list, dtype=\"float32\")\n",
        "\n",
        "#Construct training set using custom selection function\n",
        "dataset_perscut(data_path+\"TrainingSet_B1_v2.txt\",data_path+\"TrainingSet_perscut.txt\", 18) #18 is the number of header line removed\n",
        "\n",
        "#Prediction is done in mixed_precision=\"FP16C_FP32A\" to save RAM, it has almost no impact on the score\n",
        "#It could alternatively be run with a batch size of 4 to run with mixed_precision=\"FP32C_FP32A\"\n",
        "cnn.init(in_dim=i_ar([fwd_image_size,fwd_image_size]), in_nb_ch=1, out_dim=1+max_nb_obj_per_image*(7+nb_param),\n",
        "    bias=0.1, b_size=8, comp_meth=\"C_CUDA\", dynamic_load=1, mixed_precision=\"FP16C_FP32A\", adv_size=30, inference_only=1)\n",
        "\n",
        "lims = [[-6.214608098422191418e+00, -1.313647296682372989e+01],\n",
        "        [4.094344562222100414e+00 , -1.053605156578262814e-01],\n",
        "        [3.401197381662155461e+00 , -1.203972804325936119e+00]]\n",
        "\n",
        "np.savetxt(\"train_cat_norm_lims.txt\", lims)\n",
        "\n",
        "#Re-build norm, since this function can be called without data_gen_init\n",
        "\n",
        "pred_all = np.zeros((nb_images_all,fwd_image_size*fwd_image_size), dtype=\"float32\")\n",
        "patch = np.zeros((fwd_image_size,fwd_image_size), dtype=\"float32\")\n",
        "\n",
        "for i_d in range(0,nb_images_all):\n",
        "\n",
        "  p_y = int(i_d/nb_area_w)\n",
        "  p_x = int(i_d%nb_area_w)\n",
        "\n",
        "  xmin = p_x*patch_shift - orig_offset\n",
        "  xmax = p_x*patch_shift + fwd_image_size - orig_offset\n",
        "  ymin = p_y*patch_shift - orig_offset\n",
        "  ymax = p_y*patch_shift + fwd_image_size - orig_offset\n",
        "\n",
        "  px_min = 0; px_max = fwd_image_size\n",
        "  py_min = 0; py_max = fwd_image_size\n",
        "\n",
        "  set_zero = 0\n",
        "\n",
        "  if(xmin < 0):\n",
        "    px_min = -xmin; xmin = 0; set_zero = 1\n",
        "  if(ymin < 0):\n",
        "    py_min = -ymin; ymin = 0; set_zero = 1\n",
        "  if(xmax > map_pixel_size):\n",
        "    px_max = fwd_image_size - (xmax-map_pixel_size); xmax = map_pixel_size; set_zero = 1\n",
        "  if(ymax > map_pixel_size):\n",
        "    py_max = fwd_image_size - (ymax-map_pixel_size); ymax = map_pixel_size; set_zero = 1\n",
        "\n",
        "  if(set_zero):\n",
        "    patch[:,:] = 0.0\n",
        "\n",
        "  patch[py_min:py_max,px_min:px_max] = full_img[ymin:ymax,xmin:xmax]\n",
        "  patch = np.clip(patch,min_pix,max_pix)\n",
        "  patch = (patch - min_pix) / (max_pix-min_pix)\n",
        "  patch = np.tanh(3.0*patch)\n",
        "  pred_all[i_d,:] = patch.flatten(\"C\")\n",
        "\n",
        "input_data = pred_all\n",
        "nb_images_all = np.shape(input_data)[0]\n",
        "targets = np.zeros((nb_images_all,1+max_nb_obj_per_image*(7+nb_param)), dtype=\"float32\")\n",
        "\n",
        "del (full_img)\n",
        "\n",
        "cnn.create_dataset(\"TEST\", nb_images_all, input_data[:,:], targets[:,:])\n",
        "\n",
        "del (input_data, pred_all, targets)\n",
        "\n",
        "nb_yolo_filters = cnn.set_yolo_params(raw_output=0)\n",
        "\n",
        "load_epoch = 0\n",
        "if (len(sys.argv) > 1):\n",
        "    load_epoch = int(sys.argv[1])\n",
        "\n",
        "if(load_epoch > 0):\n",
        "    cnn.load(\"net_save/net0_s%04d.dat\"%load_epoch, load_epoch, bin=1)\n",
        "else:\n",
        "    if(not os.path.isfile(data_path+\"YOLO_CIANNA_ref_SDC1_i3600_s480k_MINERVA_Cornu2024.dat\")):\n",
        "            os.system(\"wget -P %s https://share.obspm.fr/s/GELFJjBFtwC4g5A/download/YOLO_CIANNA_ref_SDC1_i3600_s480k_MINERVA_Cornu2024.dat\"%(data_path))\n",
        "    cnn.load(data_path+\"YOLO_CIANNA_ref_SDC1_i3600_s480k_MINERVA_Cornu2024.dat\", 0, bin=1)\n",
        "\n",
        "cnn.forward(no_error=1, saving=2, repeat=1, drop_mode=\"AVG_MODEL\")\n",
        "\n",
        "EOF"
      ],
      "metadata": {
        "id": "-LsTUqEe7OKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Post - Processing ang visualisation\n",
        "\n",
        "Run the pred_visual.py script to generate all the figures and compute the complete score.\n",
        "\n",
        "We recommend looking at the captions in the paper for a full figure description."
      ],
      "metadata": {
        "id": "KsrdymaP8koE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/CIANNA/examples/SKAO_SDC1/\n",
        "\n",
        "from data_gen import *\n",
        "\n",
        "load_iter = 0\n",
        "\n",
        "#Obj thresholds should be optimize for specif training or iter (using post_process.py)\n",
        "\n",
        "#For best score (YOLO-CIANNA-ref)\n",
        "prob_obj_cases = np.array([0.2314, 0.1449, 0.2602, 0.1289, 0.2454, 0.2183, 0.0602, 0.0677, 0.0536])\n",
        "\n",
        "#For good precision (YOLO-CIANNA-alt)\n",
        "#prob_obj_cases = np.array([0.6102, 0.5424, 0.6441, 0.4407, 0.6271, 0.6102, 0.7119, 0.7288, 0.88])\n",
        "\n",
        "#To sample the full mAP curve (require low value for all)\n",
        "#prob_obj_cases = np.array([0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03])\n",
        "\n",
        "#Data normalization to display the dynamic of the network input\n",
        "\n",
        "for i in range(0,np.shape(full_img)[0]):\n",
        "  full_img[i,:] = np.clip(full_img[i,:], min_pix,max_pix)\n",
        "  full_img[i,:] = (full_img[i,:] - min_pix) / (max_pix-min_pix)\n",
        "  full_img[i,:] = np.tanh(3.0*full_img[i,:])\n",
        "\n",
        "full_data_norm = full_img\n",
        "del (full_img)"
      ],
      "metadata": {
        "id": "JatASNufAawx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print (\"Loading GroundTruth from TrainingSet_perscut ... \")\n",
        "\n",
        "if(not os.path.isfile(data_path+\"True_560_perscut.txt\")):\n",
        "\tdataset_perscut(data_path+\"True_560_v2.txt\",data_path+\"True_560_perscut.txt\", 0)\n",
        "target_list = np.loadtxt(data_path+\"True_560_perscut.txt\", skiprows=0)\n",
        "\n",
        "#Get the sky coordinate of all sources in the selected training catalog\n",
        "c = SkyCoord(ra=target_list[:,1] * u.deg, dec=target_list[:,2] * u.deg, frame='icrs')\n",
        "x, y = utils.skycoord_to_pixel(c, wcs_img)\n",
        "\n",
        "#Compute the bmaj and bmin in pixel size (approximate)\n",
        "#Only used to define the bouding boxes\n",
        "w = target_list[:,7]/(3600.0*pixel_size)*2\n",
        "h = target_list[:,8]/(3600.0*pixel_size)*2\n",
        "\n",
        "#Get the value of the beam for each source position as well\n",
        "xbeam, ybeam = utils.skycoord_to_pixel(c, wcs_beam)\n",
        "new_data_beam = np.nan_to_num(data_beam)\n",
        "beamval = interpn((np.arange(0,np.shape(data_beam)[0]), np.arange(0,np.shape(data_beam)[1])),\n",
        "\t\tnew_data_beam, (ybeam, xbeam), method=\"splinef2d\")\n",
        "\n",
        "n_w = np.zeros((np.shape(target_list)[0]))\n",
        "n_h = np.zeros((np.shape(target_list)[0]))\n",
        "coords = np.zeros((np.shape(target_list)[0],4))\n",
        "flux_list = np.zeros((np.shape(target_list)[0]))\n",
        "bmaj_list = np.zeros((np.shape(target_list)[0]))\n",
        "bmin_list = np.zeros((np.shape(target_list)[0]))\n",
        "pa_list   = np.zeros((np.shape(target_list)[0]))\n",
        "\n",
        "#Convert all bmaj, bmin size onto regular \"boxes\" as defined for classical detection task\n",
        "#The new box must include the source as defined by Bmaj and Bmin\n",
        "for i in range(0,np.shape(target_list)[0]):\n",
        "\tW = w[i]\n",
        "\tH = h[i]\n",
        "\tvertices = np.array([[-W*0.5,-H*0.5],[-W*0.5,H*0.5],[W*0.5, -H*0.5],[W*0.5,H*0.5]])\n",
        "\n",
        "\tvertices_new = np.zeros((4,2))\n",
        "\tvertices_new[:,0] = np.cos(target_list[i,9]*np.pi/180.0)*vertices[:,0] + np.sin(target_list[i,9]*np.pi/180.0)*vertices[:,1]\n",
        "\tvertices_new[:,1] = - np.sin(target_list[i,9]*np.pi/180.0)*vertices[:,0] + np.cos(target_list[i,9]*np.pi/180.0)*vertices[:,1]\n",
        "\n",
        "\tn_w[i] = max(vertices_new[:,0]) - min(vertices_new[:,0])\n",
        "\tn_h[i] = max(vertices_new[:,1]) - min(vertices_new[:,1])\n",
        "\n",
        "#Clip the too small boxes (in pixel size)\n",
        "n_w = np.clip(n_w, box_clip[0], box_clip[1])\n",
        "n_h = np.clip(n_h, box_clip[0], box_clip[1])\n",
        "\n",
        "#Convert the \"local\" vertice coordinates in edges coordinates using the full image size\n",
        "coords[:,0] = x - n_w[:]*0.5\n",
        "coords[:,1] = x + n_w[:]*0.5\n",
        "coords[:,2] = y - n_h[:]*0.5\n",
        "coords[:,3] = y + n_h[:]*0.5\n",
        "\n",
        "flux_list[:] = target_list[:,5]\n",
        "bmaj_list[:] = target_list[:,7]\n",
        "bmin_list[:] = target_list[:,8]\n",
        "pa_list[:]   = target_list[:,9]\n",
        "\n",
        "#Remap all the PA values so they are all in the range [-90,90]\n",
        "index = np.where((pa_list[:] > 90.0) & (pa_list[:] <= 270.0))\n",
        "pa_list[index[0]] = -90.0 + (pa_list[index[0]] - 90.0)\n",
        "index = np.where((pa_list[:] > 270.0) & (pa_list[:] < 360.0))\n",
        "pa_list[index[0]] = -90.0 + (pa_list[index[0]] - 270.0)\n",
        "\n",
        "#Get the \"apparent flux\" to correspond to the visible flux in the beam convolved map\n",
        "flux_list[:] = flux_list[:]*beamval[:]\n",
        "\n",
        "target_select_boxes = np.array([target_list[:,1],target_list[:,2],n_w,n_h,flux_list,bmaj_list,bmin_list,target_list[:,0]]).T\n",
        "\n",
        "print(\" Done!\")"
      ],
      "metadata": {
        "id": "HS0vxoDeRD3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Post process of the prediction, objectness filtering and intra-patch NMS"
      ],
      "metadata": {
        "id": "F_0KypwlBBuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Reading Network prediction ... \")\n",
        "pred_data = np.fromfile(\"fwd_res/net0_%04d.dat\"%load_iter, dtype=\"float32\")\n",
        "\n",
        "#Repeat corresponds to the number of MC_MODEL realization\n",
        "repeat = 1\n",
        "predict = np.reshape(pred_data, (repeat, nb_area_h, nb_area_w, nb_box*(8+nb_param),yolo_nb_reg,yolo_nb_reg))\n",
        "#Only keep the mean, but any realization statistic can be computed here\n",
        "predict = np.mean(predict, axis=0)\n",
        "\n",
        "print (np.shape(predict))\n",
        "print (\"1st order predictions filtering ... \")\n",
        "\n",
        "final_boxes = []\n",
        "c_tile = np.zeros((yolo_nb_reg*yolo_nb_reg*nb_box,(6+1+nb_param+1)),dtype=\"float32\")\n",
        "c_tile_kept = np.zeros((yolo_nb_reg*yolo_nb_reg*nb_box,(6+1+nb_param+1)),dtype=\"float32\")\n",
        "c_box = np.zeros((6+1+nb_param+1),dtype=\"float32\")\n",
        "patch = np.zeros((fwd_image_size, fwd_image_size), dtype=\"float32\")\n",
        "\n",
        "box_count_per_reg_hist = np.zeros((nb_box+1), dtype=\"int\")\n",
        "\n",
        "cumul_filter_box = 0; cumul_post_nms = 0\n",
        "\n",
        "for ph in tqdm(range(0,nb_area_h)):\n",
        "\tfor pw in range(0, nb_area_w):\n",
        "\n",
        "\t\tc_tile[:,:] = 0.0; c_tile_kept[:,:] = 0.0\n",
        "\n",
        "\t\tp_x = pw; p_y = ph\n",
        "\n",
        "\t\txmin = p_x*patch_shift - orig_offset\n",
        "\t\txmax = p_x*patch_shift + fwd_image_size - orig_offset\n",
        "\t\tymin = p_y*patch_shift - orig_offset\n",
        "\t\tymax = p_y*patch_shift + fwd_image_size - orig_offset\n",
        "\n",
        "\t\tpx_min = 0; px_max = fwd_image_size\n",
        "\t\tpy_min = 0; py_max = fwd_image_size\n",
        "\n",
        "\t\tif(ph == 0 or ph == nb_area_h-1 or pw == 0 or pw == nb_area_w-1):\n",
        "\t\t\tpatch[:,:] = 0.0\n",
        "\t\telse:\n",
        "\t\t\tpatch[:,:] = full_data_norm[ymin:ymax,xmin:xmax]\n",
        "\n",
        "\t\tc_pred = predict[ph,pw,:,:,:]\n",
        "\t\tc_nb_box = tile_filter(c_pred, c_box, c_tile, nb_box, prob_obj_cases, patch, val_med_lims, val_med_obj, box_count_per_reg_hist)\n",
        "\n",
        "\t\tcumul_filter_box += c_nb_box\n",
        "\t\tc_nb_box_final = c_nb_box\n",
        "\t\tc_nb_box_final = first_NMS(c_tile, c_tile_kept, c_box, c_nb_box, first_nms_thresholds, first_nms_obj_thresholds)\n",
        "\t\tcumul_post_nms += c_nb_box_final\n",
        "\n",
        "\t\t#Manually set all edge predictions to 0\n",
        "\t\t#The network was not train to interpret these cases which results in artifacts\n",
        "\t\tout_range = 2\n",
        "\t\tif(ph < out_range or ph >= nb_area_h-out_range or pw < out_range or pw >= nb_area_w-out_range):\n",
        "\t\t\tc_nb_box_final = 0\n",
        "\n",
        "\t\tfinal_boxes.append(np.copy(c_tile_kept[0:c_nb_box_final]))\n",
        "\n",
        "final_boxes = np.reshape(np.array(final_boxes, dtype=\"object\"), (nb_area_h, nb_area_w))\n",
        "\n",
        "flat_kept = np.vstack(final_boxes.flatten())\n",
        "\n",
        "print (\"NMS removed average frac:\", (cumul_filter_box-cumul_post_nms)/cumul_filter_box)\n",
        "\n"
      ],
      "metadata": {
        "id": "y7Vg_BgqA9JJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inter-patch NMS filtering"
      ],
      "metadata": {
        "id": "WDh-6l9bBKnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"2nd order predictions filtering ... \")\n",
        "\n",
        "overlap = fwd_image_size - patch_shift\n",
        "\n",
        "c_tile = np.zeros((yolo_nb_reg*yolo_nb_reg*nb_box,(6+1+nb_param+1)),dtype=\"float32\")\n",
        "\n",
        "dir_array = np.array([[-1,0],[+1,0],[0,-1],[0,+1],[-1,+1],[+1,+1],[-1,-1],[+1,-1]])\n",
        "\n",
        "#Second NMS over all the overlapping patches\n",
        "for ph in range(0, nb_area_h):\n",
        "\tfor pw in range(0, nb_area_w):\n",
        "\t\tboxes = np.copy(final_boxes[ph,pw])\n",
        "\t\tfor l in range(0,8):\n",
        "\t\t\tif(ph+dir_array[l,1] >= 0 and ph+dir_array[l,1] <= nb_area_h-1 and\t\t\t\tpw+dir_array[l,0] >= 0 and pw+dir_array[l,0] <= nb_area_w-1):\n",
        "\t\t\t\tcomp_boxes = np.copy(final_boxes[ph+dir_array[l,1],pw+dir_array[l,0]])\n",
        "\t\t\t\tc_nb_box = second_NMS_local(boxes, comp_boxes, c_tile, dir_array[l], second_nms_threshold)\n",
        "\t\t\t\tboxes = np.copy(c_tile[0:c_nb_box,:])\n",
        "\n",
        "\t\tfinal_boxes[ph,pw] = np.copy(boxes)\n",
        "\n",
        "flat_kept = np.vstack(final_boxes.flatten())\n",
        "\n",
        "print (\"Total N. of predictions kept: \", np.shape(flat_kept)[0])"
      ],
      "metadata": {
        "id": "uSvdegGXA529"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Convert predictions to source catalog in scorer format"
      ],
      "metadata": {
        "id": "MTenP8hQBO4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Order predictions by objectness score and convert to SDC scorer format\n",
        "\n",
        "final_boxes_scaled = np.copy(final_boxes)\n",
        "for p_h in range(0, nb_area_h):\n",
        "\tbox_h_offset = p_h*patch_shift - orig_offset\n",
        "\tfor p_w in range(0, nb_area_w):\n",
        "\t\tbox_w_offset = p_w*patch_shift - orig_offset\n",
        "\t\tfinal_boxes_scaled[p_h,p_w][:,0] = box_w_offset + final_boxes_scaled[p_h,p_w][:,0]\n",
        "\t\tfinal_boxes_scaled[p_h,p_w][:,2] = box_w_offset + final_boxes_scaled[p_h,p_w][:,2]\n",
        "\t\tfinal_boxes_scaled[p_h,p_w][:,1] = box_h_offset + final_boxes_scaled[p_h,p_w][:,1]\n",
        "\t\tfinal_boxes_scaled[p_h,p_w][:,3] = box_h_offset + final_boxes_scaled[p_h,p_w][:,3]\n",
        "\n",
        "flat_kept_scaled = np.vstack(final_boxes_scaled.flatten())\n",
        "flat_kept_scaled = flat_kept_scaled[flat_kept_scaled[:,5].argsort(),:][::-1]\n",
        "\n",
        "x_y_flat_kept = np.copy(flat_kept_scaled[:,0:2])\n",
        "x_y_flat_kept[:,0] = np.clip((flat_kept_scaled[:,0]+flat_kept_scaled[:,2])*0.5 - 0.5, 0, map_pixel_size)\n",
        "x_y_flat_kept[:,1] = np.clip((flat_kept_scaled[:,1]+flat_kept_scaled[:,3])*0.5 - 0.5, 0, map_pixel_size)\n",
        "\n",
        "cls = utils.pixel_to_skycoord(x_y_flat_kept[:,0], x_y_flat_kept[:,1], wcs_img)\n",
        "ra_dec_coords = np.array([cls.ra.deg, cls.dec.deg])\n",
        "w, h = flat_kept_scaled[:,2]-flat_kept_scaled[:,0], flat_kept_scaled[:,3]-flat_kept_scaled[:,1]\n",
        "\n",
        "catalog_size = np.shape(flat_kept_scaled)[0]\n",
        "cat_header = \"RA(deg), DEC(deg), X(pix), Y(pix), W(pix), H(pix), Objectness(real), Apparent Flux(Jy), BMAJ(arcsec), BMIN(arcsec), PA(degree)\"\n",
        "box_catalog = np.zeros((catalog_size,11), dtype=\"float32\")\n",
        "\n",
        "lims = np.loadtxt(\"train_cat_norm_lims.txt\")\n",
        "\n",
        "box_catalog[:,[0,1]] = ra_dec_coords.T\n",
        "box_catalog[:,[2,3]] = np.array([w[:], h[:]]).T\n",
        "box_catalog[:,4] = flat_kept_scaled[:,4]\n",
        "box_catalog[:,5] = flat_kept_scaled[:,5]\n",
        "box_catalog[:,6] = np.exp(flat_kept_scaled[:,7]*(lims[0,0] - lims[0,1]) + lims[0,1])\n",
        "box_catalog[:,7] = np.exp(flat_kept_scaled[:,8]*(lims[1,0] - lims[1,1]) + lims[1,1])\n",
        "box_catalog[:,8] = np.exp(flat_kept_scaled[:,9]*(lims[2,0] - lims[2,1]) + lims[2,1])\n",
        "box_catalog[:,9] =  np.clip(np.arctan2(np.clip(flat_kept_scaled[:,11],0.0,1.0)*2.0 - 1.0, np.clip(flat_kept_scaled[:,10],0.0,1.0))*180.0/np.pi,-90,90)\n",
        "\n",
        "coords = SkyCoord(box_catalog[:,0]*u.deg, box_catalog[:,1]*u.deg)\n",
        "index = np.where(coords.ra.deg > 90.0)\n",
        "\n",
        "ra = coords.ra.deg\n",
        "dec = coords.dec.deg\n",
        "\n",
        "ra[index[0]] -= 360.0\n",
        "\n",
        "xbeam, ybeam = utils.skycoord_to_pixel(coords, wcs_beam)\n",
        "new_data_beam = np.nan_to_num(data_beam)\n",
        "beamval = interpn((np.arange(0,np.shape(data_beam)[0]), np.arange(0,np.shape(data_beam)[1])),\n",
        "\t\tnew_data_beam, (ybeam, xbeam), method=\"splinef2d\")\n",
        "\n",
        "FLUX_JY = box_catalog[:,6]/beamval\n",
        "\n",
        "empty = np.zeros((np.shape(coords.ra.deg)[0]))\n",
        "print (np.arange(0,np.shape(box_catalog)[0]))\n",
        "scoring_table = np.vstack((np.arange(0,np.shape(box_catalog)[0]), ra, dec, ra, dec,\n",
        "\t\t\t\t\t\tFLUX_JY, empty+0.0375, box_catalog[:,7], box_catalog[:,8],\n",
        "\t\t\t\t\t\tbox_catalog[:,9], empty+2.0, empty+3.0))\n",
        "\n",
        "np.savetxt(data_path+\"YOLO_CIANNA_sdc1_catalog.txt\", scoring_table.T, fmt=\"%d %1.8f %2.8f %1.8f %2.8f %g %0.8f %f %f %f %d %d\")\n",
        "\n",
        "del(final_boxes_scaled, final_boxes, predict, pred_data, scoring_table, c_pred)"
      ],
      "metadata": {
        "id": "ifw1plOuBSXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Score the source catalog"
      ],
      "metadata": {
        "id": "VjoqZ33qBTOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#See the pred_visual.py script for instruction on how to score a catalog from another team\n",
        "\n",
        "sub_cat_path = data_path+\"YOLO_CIANNA_sdc1_catalog.txt\"; c_mode=0; skip_cat = 0\n",
        "\n",
        "truth_cat_path = data_path+\"True_560_v2.txt\"\n",
        "skip_cat = 0\n",
        "skip_truth = 0\n",
        "\n",
        "scorer = Sdc1Scorer.from_txt(sub_cat_path, truth_cat_path, freq=560, sub_skiprows=skip_cat, truth_skiprows=skip_truth)\n",
        "\n",
        "scorer.run(mode=0, # 0, 1 for core, centroid position modes respectively\n",
        "\ttrain=False, # True to score based on training area only, else exclude\n",
        "\tdetail=True, # True to return per-source scores and match catalogue\n",
        "\t)\n",
        "\n",
        "print(\"Final score: {}\".format(scorer.score.value))\n",
        "\n",
        "print (\"Ndet:\", scorer.score.n_det)\n",
        "print (\"Nmatch:\", scorer.score.n_match)\n",
        "print (\"Nbad:\", scorer.score.n_bad)\n",
        "print (\"Nfalse:\", scorer.score.n_false)\n",
        "print (\"Score det:\",scorer.score.score_det)\n",
        "print (\"Average match score:\",scorer.score.acc_pc)\n",
        "\n",
        "\"\"\"\n",
        "id, ra_core, dec_core, ra_cent, dec_cent, flux, core_frac, b_maj, b_min, pa, size_id, class, a_flux, conv_size, id_t, ra_core_t, dec_core_t\n",
        "ra_cent_t, dec_cent_t, flux_t, core_frac_t, b_maj_t, b_min_t, pa_t, size_id_t, class_t, a_flux_t, conv_size_t, multi_d_err\n",
        "\"\"\"\n",
        "\n",
        "matched = scorer.score.match_df\n",
        "scores_df = scorer.score.scores_df\n",
        "\n",
        "cat_dat = np.loadtxt(sub_cat_path, skiprows=skip_cat)\n",
        "truth_dat = np.loadtxt(truth_cat_path, skiprows=0)\n",
        "\n",
        "ra_min = -0.6723; ra_max = 0.0; dec_min = -29.9400; dec_max = -29.4061\n",
        "\n",
        "print (np.shape(truth_dat))\n",
        "index = np.where((truth_dat[:,1] < ra_max) & (truth_dat[:,1] > ra_min) &\n",
        "\t\t\t\t (truth_dat[:,2] < dec_max) & (truth_dat[:,2] > dec_min))\n",
        "\n",
        "truth_dat = np.delete(truth_dat,index,axis=0)\n",
        "full_truth_cat_size = np.shape(truth_dat)[0]\n",
        "print (np.shape(truth_dat))\n",
        "\n",
        "print(\"Avg. pos score:\",np.mean(scores_df[\"position\"]))\n",
        "print(\"Avg. bmaj score:\",np.mean(scores_df[\"b_maj\"]))\n",
        "print(\"Avg. bmin score:\",np.mean(scores_df[\"b_min\"]))\n",
        "print(\"Avg. flux score:\",np.mean(scores_df[\"flux\"]))\n",
        "print(\"Avg. PA score:\",np.mean(scores_df[\"pa\"]))\n",
        "print(\"Avg. cf score:\",np.mean(scores_df[\"core_frac\"]))\n",
        "print(\"Avg. class score:\",np.mean(scores_df[\"class\"]))\n",
        "\n",
        "print(\"Precision / Reliability:\", scorer.score.n_match/scorer.score.n_det)\n",
        "print(\"(With bad) Precision / Reliability:\", (scorer.score.n_match+scorer.score.n_bad)/scorer.score.n_det)\n",
        "\n",
        "#Results with vary slightly with the YOLO-CIANNA-ref save model compared to Cornu et al. if prediction is made with mixed_precision=\"FP16C_FP32A\""
      ],
      "metadata": {
        "id": "ElqM2ikOBWz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Detected sources over examples fields"
      ],
      "metadata": {
        "id": "ZenjHO7uBmpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_fields = 3\n",
        "fields = np.array([[0.1,-30.2],\n",
        "\t\t\t\t   [1.22,-29.60],\n",
        "\t\t\t\t   [-1.74,-30.14]])\n",
        "\n",
        "def sim_360(val):\n",
        "\ttab = np.copy(val)\n",
        "\tfor i in range(0,len(tab)):\n",
        "\t\tif (tab[i] > 180):\n",
        "\t\t\ttab[i] = tab[i]-360.0\n",
        "\treturn tab\n",
        "\n",
        "def sim_360_rev(val):\n",
        "\ttab = np.copy(val)\n",
        "\tfor i in range(0,len(tab)):\n",
        "\t\tif (tab[i] < 0):\n",
        "\t\t\ttab[i] = 360.0 + tab[i]\n",
        "\treturn tab\n",
        "\n",
        "cutout_size = 256\n",
        "deg_size = cutout_size*1.2*pixel_size\n",
        "\n",
        "id_loc_mask = np.isin(target_select_boxes[:,-1], matched.id_t.to_numpy())\n",
        "id_loc_found = np.where(id_loc_mask)\n",
        "\n",
        "target_missed = np.delete(target_select_boxes, id_loc_found, axis=0)\n",
        "id_loc_mask = np.isin(matched.id_t.to_numpy(), target_select_boxes[:,-1])\n",
        "\n",
        "id_loc_found = np.where(id_loc_mask == True)[0]\n",
        "id_loc_not_found = np.where(id_loc_mask == False)[0]\n",
        "\n",
        "flagged_boxes = np.zeros((np.shape(box_catalog)[0],np.shape(box_catalog)[1]+1))\n",
        "flagged_boxes[:,:-1] = box_catalog[:,:]\n",
        "\n",
        "flagged_boxes[matched.id.to_numpy()[id_loc_found],-1] = 1\n",
        "flagged_boxes[matched.id.to_numpy()[id_loc_not_found],-1] = 2\n",
        "\n",
        "fig, axs = plt.subplots(nb_fields, 3, figsize=(15.2,5*nb_fields), dpi=60,\n",
        "\tgridspec_kw={'width_ratios': [1, 1, 1]}, constrained_layout=True)\n",
        "\n",
        "for run_f in range(0,nb_fields):\n",
        "\n",
        "\tprint(\"Coords: ra: %f (deg) dec: %f (deg)\", fields[run_f,0], fields[run_f,1])\n",
        "\tpatch = Cutout2D(full_data_norm, SkyCoord(ra=fields[run_f,0]*u.deg, dec=fields[run_f,1]*u.deg, frame=\"icrs\"),\n",
        "\t\t\t\t\t (cutout_size,cutout_size), wcs_img.celestial)\n",
        "\n",
        "\tfor i in range(0,3):\n",
        "\t\tgcf = axs[run_f,i].imshow(patch.data, cmap=\"hot\", vmax = 0.5*1.0, vmin = 0)\n",
        "\n",
        "\t\taxs[run_f,i].set_xlim(-0.5,cutout_size-0.5)\n",
        "\t\taxs[run_f,i].set_ylim(-0.5,cutout_size-0.5)\n",
        "\n",
        "\t\taxs[run_f,i].tick_params(axis='y', which='both', left=False, labelleft=False, right=False, labelright=False)\n",
        "\t\taxs[run_f,i].tick_params(axis='x', which='both', bottom=False, labelbottom=False, top=False, labeltop=False)\n",
        "\n",
        "\tmissed_kept_id = np.where((np.abs(target_missed[:,0] - fields[run_f,0]) < deg_size*0.5) &\n",
        "\t\t\t   (np.abs(target_missed[:,1] - fields[run_f,1]) < deg_size*0.5))[0]\n",
        "\ttarget_missed_kept = target_missed[missed_kept_id,:]\n",
        "\n",
        "\tfull_truth_kept_id =  np.where((np.abs(truth_dat[:,1] - fields[run_f,0]) < deg_size*0.5) &\n",
        "\t\t\t   (np.abs(truth_dat[:,2] - fields[run_f,1]) < deg_size*0.5))[0]\n",
        "\n",
        "\tprint (np.min(flagged_boxes[:,0]), np.max(flagged_boxes[:,0]))\n",
        "\tkept_boxes_id = np.where((np.abs(sim_360(flagged_boxes[:,0]) - fields[run_f,0]) < deg_size*0.5) &\n",
        "\t\t\t\t(np.abs(flagged_boxes[:,1] - fields[run_f,1] < deg_size*0.5)))[0]\n",
        "\tkept_boxes_pred = flagged_boxes[kept_boxes_id,:]\n",
        "\tprint (np.shape(kept_boxes_pred))\n",
        "\n",
        "\tpx, py = utils.skycoord_to_pixel(SkyCoord(sim_360_rev(truth_dat[full_truth_kept_id,1])*u.deg,\n",
        "\t\t\t\ttruth_dat[full_truth_kept_id,2]*u.deg, frame=\"icrs\"), wcs=patch.wcs.celestial)\n",
        "\n",
        "\tif(np.shape(px)[0] > 0):\n",
        "\t\taxs[run_f,0].scatter(px, py, c=\"green\", s=4.0,lw=0.6,\n",
        "\t\t\t\t\t   marker=\"x\", alpha=1.0, label=\"All True\")\n",
        "\t\taxs[run_f,0].set_title(\"Field %d\"%(run_f+1), fontweight=\"bold\", fontsize=16,\n",
        "\t\t\t\t\t\t\t\trotation=\"vertical\",x=-0.15,y=0.5, verticalalignment=\"center\", horizontalalignment=\"center\")\n",
        "\t\taxs[run_f,0].text(-16,cutout_size*0.5, \"RA=%0.2f, Dec=%0.2f [deg]\"%(fields[run_f,0], fields[run_f,1]), fontsize=14,\n",
        "\t\t\t\t\t\t  rotation=\"vertical\", verticalalignment=\"center\", horizontalalignment=\"center\")\n",
        "\n",
        "\tpx, py = utils.skycoord_to_pixel(SkyCoord(sim_360_rev(kept_boxes_pred[:,0])*u.deg,kept_boxes_pred[:,1]*u.deg, frame=\"icrs\"), wcs=patch.wcs.celestial)\n",
        "\n",
        "\tfor i in range(0, np.shape(kept_boxes_pred)[0]):\n",
        "\n",
        "\t\txmin = px[i] - kept_boxes_pred[i,2]*0.5\n",
        "\t\tymin = py[i] - kept_boxes_pred[i,3]*0.5\n",
        "\t\txmax = px[i] + kept_boxes_pred[i,2]*0.5\n",
        "\t\tymax = py[i] + kept_boxes_pred[i,3]*0.5\n",
        "\n",
        "\t\tif(kept_boxes_pred[i,-1] == 1):\n",
        "\t\t\tel = patches.Rectangle((xmin,ymin), (xmax-xmin), (ymax-ymin), linewidth=0.7, ls=\"-\", fill=False, color=\"dodgerblue\", zorder=3)\n",
        "\t\t\tc_patch = axs[run_f,1].add_patch(el)\n",
        "\t\t\tc_patch.set_path_effects([path_effects.Stroke(linewidth=1.8, foreground='black'),\n",
        "\t\t\t\t\t   path_effects.Normal()])\n",
        "\t\telif(kept_boxes_pred[i,-1] == 2):\n",
        "\t\t\tel = patches.Rectangle((xmin,ymin), (xmax-xmin), (ymax-ymin), linewidth=0.7, ls=\"-\", fill=False, color=\"aqua\", zorder=3)\n",
        "\t\t\tc_patch = axs[run_f,1].add_patch(el)\n",
        "\t\t\tc_patch.set_path_effects([path_effects.Stroke(linewidth=1.8, foreground='black'),\n",
        "\t\t\t\t\t   path_effects.Normal()])\n",
        "\t\telse:\n",
        "\t\t\tel = patches.Rectangle((xmin,ymin), (xmax-xmin), (ymax-ymin), linewidth=0.7, ls=\"-\", fill=False, color=\"violet\", zorder=3)\n",
        "\t\t\tc_patch = axs[run_f,2].add_patch(el)\n",
        "\t\t\tc_patch.set_path_effects([path_effects.Stroke(linewidth=1.8, foreground='black'),\n",
        "\t\t\t\t\t   path_effects.Normal()])\n",
        "\n",
        "\tpx, py = utils.skycoord_to_pixel(SkyCoord(target_missed_kept[:,0]*u.deg,target_missed_kept[:,1]*u.deg, frame=\"icrs\"), wcs=patch.wcs.celestial)\n",
        "\n",
        "\tfor i in range(0, np.shape(target_missed_kept)[0]):\n",
        "\n",
        "\t\txmin = px[i] - target_missed_kept[i,2]*0.5\n",
        "\t\tymin = py[i] - target_missed_kept[i,3]*0.5\n",
        "\t\txmax = px[i] + target_missed_kept[i,2]*0.5\n",
        "\t\tymax = py[i] + target_missed_kept[i,3]*0.5\n",
        "\n",
        "\t\tel = patches.Rectangle((xmin,ymin), (xmax-xmin), (ymax-ymin), linewidth=0.8, ls=\"-\", fill=False, color=\"lightgreen\", zorder=2)\n",
        "\t\tc_patch = axs[run_f,2].add_patch(el)\n",
        "\t\tc_patch.set_path_effects([path_effects.Stroke(linewidth=1.6, foreground='black'),\n",
        "\t\t\t\t\t   path_effects.Normal()])\n",
        "\n",
        "\n",
        "\tif(run_f == 0):\n",
        "\t\tsc_handle, sc_label = axs[run_f,0].get_legend_handles_labels()\n",
        "\n",
        "\t\tmatch_in_label = patches.Patch(color=\"dodgerblue\", label=\"Match In\", linewidth=2.0, fill=False)\n",
        "\t\tmatch_in_label.set_path_effects([path_effects.Stroke(linewidth=4.0, foreground='black'),\n",
        "\t\t\t\t\t   path_effects.Normal()])\n",
        "\n",
        "\t\tmatch_out_label = patches.Patch(color=\"aqua\", label=\"Match Out\", linewidth=2.0, fill=False)\n",
        "\t\tmatch_out_label.set_path_effects([path_effects.Stroke(linewidth=4.0, foreground='black'),\n",
        "\t\t\t\t\t   path_effects.Normal()])\n",
        "\n",
        "\t\tmatch_false_label = patches.Patch(color=\"violet\", label=\"Bad / False\", linewidth=2.0, fill=False)\n",
        "\t\tmatch_false_label.set_path_effects([path_effects.Stroke(linewidth=4.0, foreground='black'),\n",
        "\t\t\t\t\t   path_effects.Normal()])\n",
        "\n",
        "\t\tmatch_missed_label = patches.Patch(color=\"lightgreen\", label=\"Missed In\", linewidth=2.0, fill=False)\n",
        "\t\tmatch_missed_label.set_path_effects([path_effects.Stroke(linewidth=4.0, foreground='black'),\n",
        "\t\t\t\t\t   path_effects.Normal()])\n",
        "\n",
        "\t\tleg1 = axs[run_f,0].legend(handles=sc_handle, loc=\"upper center\", bbox_to_anchor=(0.5,1.18),\n",
        "\t\t\tfancybox=False, shadow=True, ncol=1, fontsize=17, markerscale=2.0)\n",
        "\t\tleg1.legendHandles[0]._sizes = [100]\n",
        "\t\tleg1.legendHandles[0].set_linewidth(2.0)\n",
        "\n",
        "\t\tleg2 = axs[run_f,1].legend(handles=[match_in_label,match_out_label], loc=\"upper center\", bbox_to_anchor=(0.5,1.18),\n",
        "\t\t\tfancybox=False, shadow=True, ncol=2, fontsize=17, markerscale=2.0)\n",
        "\t\tleg3 = axs[run_f,2].legend(handles=[match_false_label,match_missed_label], loc=\"upper center\", bbox_to_anchor=(0.5,1.18),\n",
        "\t\t\tfancybox=False, shadow=True, ncol=2, fontsize=17, markerscale=2.0)\n",
        "\n",
        "\t\tleg1.get_frame().set_linewidth(1.8)\n",
        "\t\tleg1.get_frame().set_edgecolor(\"black\")\n",
        "\t\tleg2.get_frame().set_linewidth(1.8)\n",
        "\t\tleg2.get_frame().set_edgecolor(\"black\")\n",
        "\t\tleg3.get_frame().set_linewidth(1.8)\n",
        "\t\tleg3.get_frame().set_edgecolor(\"black\")\n",
        "\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "pkAyxxUCBr3e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}